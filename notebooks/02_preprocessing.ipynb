{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74cf61aa",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "\n",
    "Based on findings from `01_explore_data.ipynb`, implementing comprehensive preprocessing pipeline.\n",
    "\n",
    "## Preprocessing Steps\n",
    "\n",
    "During one pass over the data, we will do the following preprocessing steps.\n",
    "\n",
    "1. **Convert pseudo-RGB to grayscale** (automatic with cv2.IMREAD_GRAYSCALE)\n",
    "2. **Resize to 224Ã—224 pixels** (standardize for CNN input)\n",
    "3. **Apply CLAHE** (enhance contrast + normalize quality variations)\n",
    "\n",
    "Then, we can focus on some further cleanup after the initial preprocessing is complete.\n",
    "\n",
    "4. **Remove duplicates** (if found during processing)\n",
    "5. **Create train/val/test splits** (this is already done for us in the Kaggle dataset)\n",
    "6. **Address class imbalance** (augmentation for no_tumor class)\n",
    "\n",
    "**Note:** Outlier removal skipped - CLAHE normalizes quality variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c7805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure basic logging to a file\n",
    "logging.basicConfig(\n",
    "    filename='duplicates.log',  # Name of the log file\n",
    "    level=logging.INFO,  # Minimum logging level to capture (INFO, DEBUG, WARNING, ERROR, CRITICAL)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Format of log messages\n",
    "    filemode='a'  # 'a' for append (default), 'w' for overwrite\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5663a4",
   "metadata": {},
   "source": [
    "## Preprocessing Steps 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bfcff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b74b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  target_size: (224, 224)\n",
      "  apply_clahe: True\n",
      "  clahe_clip_limit: 2.0\n",
      "  clahe_tile_size: (8, 8)\n",
      "  random_seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing configuration\n",
    "config = {\n",
    "    'target_size': (224, 224),\n",
    "    'apply_clahe': True,\n",
    "    'clahe_clip_limit': 2.0,\n",
    "    'clahe_tile_size': (8, 8),\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "# Paths\n",
    "raw_dataset = Path(\"../data/brain_tumor_dataset\")\n",
    "processed_dataset = Path(\"../data/processed\")\n",
    "\n",
    "# create processed dataset directory if it doesn't exist\n",
    "processed_dataset.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Splits & Classes\n",
    "splits = ['Training','Testing']\n",
    "classes = ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor', 'no_tumor']\n",
    "\n",
    "# create subdirectories for splits and classes\n",
    "for split in splits:\n",
    "    for cls in classes:\n",
    "        dir_path = processed_dataset / split / cls\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "011f3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_hashes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe1b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_hash(image_path):\n",
    "    \"\"\"Compute Perceptual Hash of an image\"\"\"\n",
    "\n",
    "    img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to read image: {img}\")\n",
    "\n",
    "    img_hash = cv2.img_hash.pHash(img).tobytes()\n",
    "\n",
    "    return img_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a8374d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=(224,224), equalization=True):\n",
    "    \"\"\"\n",
    "    Apply all preprocessing steps to a single image.\n",
    "    \n",
    "    Args:\n",
    "        img_path: Path to input image\n",
    "        target_size: Target image size (height, width)\n",
    "        hist_normalization: Whether to apply histogram equalization\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed grayscale image (numpy array)\n",
    "    \"\"\"\n",
    "\n",
    "    # read image as grayscale\n",
    "    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None:\n",
    "            raise ValueError(f\"Failed to read image: {img_path}\")\n",
    "    \n",
    "    # resize so all images are the same size\n",
    "    img = cv2.resize(img, target_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # apply clahe equalization\n",
    "    if equalization:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        img = clahe.apply(img)\n",
    "        \n",
    "    return img\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e9a36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_dataset(raw_dir, target_dir, config, visualize_n_duplicates=0):\n",
    "    \"\"\"\n",
    "    Process entire raw dataset and save to new folder\n",
    "    \n",
    "    Args:\n",
    "        raw_dir: Path to raw dataset\n",
    "        target_dir: Path to save preprocessed dataset\n",
    "        config: Dictionary with preprocessing parameters\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with processing statistics\n",
    "    \"\"\"\n",
    "\n",
    "    raw_path = Path(raw_dir)\n",
    "    target_path = Path(target_dir)\n",
    "\n",
    "    if not target_path.exists():\n",
    "        os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "    duplicate_example = 0\n",
    "\n",
    "    # total images counts all images processed\n",
    "    # class_counts is a dictionary that holds image counts per class\n",
    "    stats = {'total_images': 0, \n",
    "             'class_counts': {}, \n",
    "             'duplicate_count': 0,\n",
    "             'failed': []\n",
    "    }    \n",
    "\n",
    "    for split in splits:\n",
    "        print(f\"Processing {split} set...\")\n",
    "        \n",
    "        for cls in classes:\n",
    "            print(f\"  Class: {cls}\")\n",
    "            class_path_raw = raw_path / split / cls\n",
    "            class_path_target = target_path / split / cls\n",
    "\n",
    "            # iterate through each class folder\n",
    "            for filename in os.listdir(class_path_raw):\n",
    "\n",
    "                # skip hidden files and non-image files\n",
    "                if filename.startswith('.') or not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                    continue\n",
    "\n",
    "\n",
    "                try:\n",
    "                    img_path_raw = class_path_raw / filename\n",
    "                    img_path_target = class_path_target / filename\n",
    "\n",
    "                    # preprocess image\n",
    "                    img = preprocess_image(img_path_raw,\n",
    "                                        target_size=config['target_size'],\n",
    "                                        equalization=config['apply_clahe']\n",
    "                    )\n",
    "\n",
    "                    # compute image hash for duplicate detection\n",
    "                    img_hash = get_image_hash(img_path_raw)\n",
    "\n",
    "                    # # check for duplicates\n",
    "                    # if img_hash in image_hashes.keys():\n",
    "                    #     stats['duplicate_count'] += 1\n",
    "                    #     logging.info(f\"Duplicate found: {img_path_raw} is a duplicate of {image_hashes[img_hash]}\")\n",
    "\n",
    "                    #     # visualize duplicates if requested\n",
    "                    #     if visualize_n_duplicates > 0 and duplicate_example < visualize_n_duplicates:\n",
    "\n",
    "                    #         duplicate_example += 1\n",
    "                    #         img1 = img\n",
    "                    #         img2 = cv2.imread(str(image_hashes[img_hash]), cv2.IMREAD_GRAYSCALE) # duplicate image\n",
    "\n",
    "                    #         plt.figure(figsize=(8,4))\n",
    "                    #         plt.suptitle(f\"Duplicate Pair: class {cls} {duplicate_example}\")\n",
    "\n",
    "                    #         plt.subplot(1,2,1)\n",
    "                    #         plt.title(f\"Image 1: {filename}\")\n",
    "                    #         plt.imshow(img1, cmap='gray')\n",
    "                    #         plt.axis('off')\n",
    "\n",
    "                    #         plt.subplot(1,2,2)\n",
    "                    #         plt.title(f\"Image 2: {image_hashes[img_hash].name}\")\n",
    "                    #         plt.imshow(img2, cmap='gray')\n",
    "                    #         plt.axis('off')\n",
    "\n",
    "                    #         plt.show()\n",
    "                    #     continue\n",
    "\n",
    "                    # save to target folder\n",
    "                    if not class_path_target.exists():\n",
    "                        os.makedirs(class_path_target, exist_ok=True)\n",
    "\n",
    "                    cv2.imwrite(str(img_path_target), img)\n",
    "                    stats['total_images'] += 1\n",
    "                    if cls not in stats['class_counts']:\n",
    "                        stats['class_counts'][cls] = 0\n",
    "                    stats['class_counts'][cls] += 1\n",
    "\n",
    "                    # store image hash\n",
    "                    image_hashes[img_hash] = img_path_target # key: image hash, value: target filepath\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process image {img_path_raw}: {e}\")\n",
    "                    stats['failed'].append((str(filename), str(e)))\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d8ae545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Training set...\n",
      "  Class: glioma_tumor\n",
      "  Class: meningioma_tumor\n",
      "  Class: pituitary_tumor\n",
      "  Class: no_tumor\n",
      "Processing Testing set...\n",
      "  Class: glioma_tumor\n",
      "  Class: meningioma_tumor\n",
      "  Class: pituitary_tumor\n",
      "  Class: no_tumor\n",
      "Preprocessing complete!\n",
      "Total images processed: 3264\n",
      "Total duplicates found and skipped: 0\n",
      "  glioma_tumor: 926 images\n",
      "  meningioma_tumor: 937 images\n",
      "  pituitary_tumor: 901 images\n",
      "  no_tumor: 500 images\n"
     ]
    }
   ],
   "source": [
    "stats = preprocess_and_save_dataset(raw_dataset, processed_dataset, config, visualize_n_duplicates=3)\n",
    "print(\"Preprocessing complete!\")\n",
    "print(f\"Total images processed: {stats['total_images']}\")\n",
    "print(f\"Total duplicates found and skipped: {stats['duplicate_count']}\")\n",
    "for cls, count in stats['class_counts'].items():\n",
    "    print(f\"  {cls}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_preprocessing_effects(sample_image_path):\n",
    "    \"\"\"\n",
    "    Visualize the effects of preprocessing on a sample image.\n",
    "    Args:\n",
    "        sample_image_path: Path to a sample raw image\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    raw_img = cv2.imread(str(sample_image_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    preprocessed_img = preprocess_image(sample_image_path,\n",
    "                                    target_size=config['target_size'],\n",
    "                                    equalization=config['apply_clahe']\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.suptitle(f\"Preprocessing Effects on: {sample_image_path.name}\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Raw Image\")\n",
    "    plt.imshow(raw_img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Preprocessed Image\")\n",
    "    plt.imshow(preprocessed_img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a few examples of preprocessed images before & after\n",
    "def display_preprocessed_examples(raw_dir, processed_dir, classes, num_examples=3):\n",
    "    raw_path = Path(raw_dir)\n",
    "    processed_path = Path(processed_dir)\n",
    "\n",
    "    for cls in classes:\n",
    "        class_path_raw = raw_path / 'Training' / cls\n",
    "        class_path_processed = processed_path / 'Training' / cls\n",
    "\n",
    "        example_files = os.listdir(class_path_raw)[:num_examples]\n",
    "\n",
    "        for filename in example_files:\n",
    "            raw_img_path = class_path_raw / filename\n",
    "            visualize_preprocessing_effects(raw_img_path)\n",
    "\n",
    "display_preprocessed_examples(raw_dataset, processed_dataset, classes, num_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d13e7e8",
   "metadata": {},
   "source": [
    "## Create Validation Split\n",
    "\n",
    "The Kaggle dataset only has Training/Testing. Create validation set from Training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737aa074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_split(processed_dir, val_size=0.2, random_seed=42):\n",
    "    \"\"\"\n",
    "    Create a validation split from the training data.\n",
    "    \n",
    "    Args:\n",
    "        processed_dir: Path to processed dataset\n",
    "        val_size: Proportion of training data to use for validation\n",
    "        random_seed: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "\n",
    "    processed_path = Path(processed_dir)\n",
    "    training_path = processed_path / 'Training'\n",
    "    validation_path = processed_path / 'Validation'\n",
    "\n",
    "    if not validation_path.exists():\n",
    "        os.makedirs(validation_path, exist_ok=True)\n",
    "        \n",
    "    for cls in classes:\n",
    "        class_path_train = training_path / cls\n",
    "        class_path_val = validation_path / cls\n",
    "\n",
    "        if not class_path_val.exists():\n",
    "            os.makedirs(class_path_val, exist_ok=True)\n",
    "\n",
    "        image_files = os.listdir(class_path_train)\n",
    "        train_files, val_files = train_test_split(image_files, test_size=val_size, random_state=random_seed)\n",
    "\n",
    "        for filename in val_files:\n",
    "            src_path = class_path_train / filename\n",
    "            dst_path = class_path_val / filename\n",
    "\n",
    "            # move file to validation folder\n",
    "            os.rename(src_path, dst_path)\n",
    "    print(\"Validation split created.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a11c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_validation_split(processed_dataset, val_size=0.2, random_seed=config['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634646e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class Distribution After Preprocessing and Split\n",
    "def compute_class_distribution(processed_dir):\n",
    "    \"\"\"\n",
    "    Compute and display class distribution in each dataset split.\n",
    "    \n",
    "    Args:\n",
    "        processed_dir: Path to processed dataset\n",
    "    \"\"\"\n",
    "\n",
    "    processed_path = Path(processed_dir)\n",
    "\n",
    "    for split in ['Training', 'Validation', 'Testing']:\n",
    "        split_path = processed_path / split\n",
    "        print(f\"Class distribution in {split} set:\")\n",
    "        for cls in classes:\n",
    "            class_path = split_path / cls\n",
    "            count = len(os.listdir(class_path))\n",
    "            print(f\"  {cls}: {count} images\")\n",
    "        print()\n",
    "\n",
    "compute_class_distribution(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a803fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_splits_distribution(processed_dir):\n",
    "    \"\"\"\n",
    "    Visualize class distribution for all splits in a 2x2 grid.\n",
    "    \n",
    "    Args:\n",
    "        processed_dir: Path to processed dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_path = Path(processed_dir)\n",
    "    splits_to_plot = ['Training', 'Validation', 'Testing']\n",
    "    \n",
    "    # Create 2x2 grid (4th subplot will be empty or used for summary)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Class Distribution Across All Splits', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, split in enumerate(splits_to_plot):\n",
    "        split_path = processed_path / split\n",
    "        \n",
    "        if not split_path.exists():\n",
    "            continue\n",
    "            \n",
    "        class_counts = {}\n",
    "        for cls in classes:\n",
    "            class_path = split_path / cls\n",
    "            if class_path.exists():\n",
    "                count = len([f for f in os.listdir(class_path) \n",
    "                           if not f.startswith('.')])\n",
    "                class_counts[cls] = count\n",
    "            else:\n",
    "                class_counts[cls] = 0\n",
    "        \n",
    "        # Calculate position\n",
    "        row = idx // 2\n",
    "        col = idx % 2\n",
    "        \n",
    "        # Plot bar chart\n",
    "        axes[row, col].bar(class_counts.keys(), class_counts.values(), color='steelblue')\n",
    "        axes[row, col].set_xlabel('Class', fontsize=10)\n",
    "        axes[row, col].set_ylabel('Number of Images', fontsize=10)\n",
    "        axes[row, col].set_title(f'{split} Set', fontsize=12, fontweight='bold')\n",
    "        axes[row, col].tick_params(axis='x', rotation=45)\n",
    "        axes[row, col].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Use 4th subplot for total counts across all splits\n",
    "    all_counts = {}\n",
    "    for cls in classes:\n",
    "        total = 0\n",
    "        for split in splits_to_plot:\n",
    "            class_path = processed_path / split / cls\n",
    "            if class_path.exists():\n",
    "                total += len([f for f in os.listdir(class_path) \n",
    "                            if not f.startswith('.')])\n",
    "        all_counts[cls] = total\n",
    "    \n",
    "    axes[1, 1].bar(all_counts.keys(), all_counts.values(), color='coral')\n",
    "    axes[1, 1].set_xlabel('Class', fontsize=10)\n",
    "    axes[1, 1].set_ylabel('Number of Images', fontsize=10)\n",
    "    axes[1, 1].set_title('Total (All Splits)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the new function\n",
    "visualize_all_splits_distribution(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e734b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(processed_dir):\n",
    "    \"\"\"\n",
    "    Calculate class weights for handling imbalance during training.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (class_weights dict, class_counts dict)\n",
    "    \n",
    "    Class_weights are calculated as: total_samples / (num_classes * count_per_class)\n",
    "    Class_weights dict maps class index to its weight.\n",
    "    Class_counts dict maps class index to its sample count.\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_path = Path(processed_dir)\n",
    "    training_path = processed_path / 'Training'\n",
    "    \n",
    "    # Count samples per class in training set\n",
    "    class_counts = {}\n",
    "    for idx, cls in enumerate(classes):\n",
    "        class_path = training_path / cls\n",
    "        if class_path.exists():\n",
    "            count = len([f for f in os.listdir(class_path) \n",
    "                        if not f.startswith('.')])\n",
    "            class_counts[idx] = count\n",
    "    \n",
    "    # Calculate weights: total / (num_classes * count_per_class)\n",
    "    total_samples = sum(class_counts.values())\n",
    "    num_classes = len(class_counts)\n",
    "    \n",
    "    class_weights = {}\n",
    "    for idx, count in class_counts.items():\n",
    "        class_weights[idx] = total_samples / (num_classes * count)\n",
    "    \n",
    "    return class_weights, class_counts\n",
    "\n",
    "def save_preprocessing_metadata(processed_dir, config, stats):\n",
    "    \"\"\"\n",
    "    Save comprehensive preprocessing metadata for reproducibility.\n",
    "    \n",
    "    Args:\n",
    "        processed_dir: Path to processed dataset\n",
    "        config: Preprocessing configuration dictionary\n",
    "        stats: Processing statistics from preprocessing\n",
    "        \n",
    "    Returns:\n",
    "        Path to saved metadata file\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_path = Path(processed_dir)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights, training_counts = calculate_class_weights(processed_dir)\n",
    "    \n",
    "    # Get distribution across all splits\n",
    "    distribution = {}\n",
    "    for split in ['Training', 'Validation', 'Testing']:\n",
    "        split_path = processed_path / split\n",
    "        if not split_path.exists():\n",
    "            continue\n",
    "            \n",
    "        distribution[split] = {}\n",
    "        for idx, cls in enumerate(classes):\n",
    "            class_path = split_path / cls\n",
    "            if class_path.exists():\n",
    "                count = len([f for f in os.listdir(class_path) \n",
    "                           if not f.startswith('.')])\n",
    "                distribution[split][cls] = count\n",
    "    \n",
    "    # Calculate imbalance ratio\n",
    "    if training_counts:\n",
    "        max_count = max(training_counts.values())\n",
    "        min_count = min(training_counts.values())\n",
    "        imbalance_ratio = max_count / min_count\n",
    "        minority_idx = min(training_counts, key=training_counts.get)\n",
    "        majority_idx = max(training_counts, key=training_counts.get)\n",
    "    else:\n",
    "        imbalance_ratio = 1.0\n",
    "        minority_idx = 0\n",
    "        majority_idx = 0\n",
    "    \n",
    "    # Create metadata dictionary\n",
    "    metadata = {\n",
    "        'preprocessing_info': {\n",
    "            'timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'config': config,\n",
    "            'total_processed': stats['total_images'],\n",
    "            'duplicates_removed': stats['duplicate_count'],\n",
    "            'failed_images': len(stats.get('failed', []))\n",
    "        },\n",
    "        'class_mapping': {\n",
    "            str(idx): cls for idx, cls in enumerate(classes)\n",
    "        },\n",
    "        'class_distribution': distribution,\n",
    "        'class_weights': {\n",
    "            str(k): float(v) for k, v in class_weights.items()  # JSON serializable\n",
    "        },\n",
    "        'imbalance_info': {\n",
    "            'imbalance_ratio': round(imbalance_ratio, 2),\n",
    "            'minority_class': classes[minority_idx],\n",
    "            'majority_class': classes[majority_idx],\n",
    "            'recommendation': 'Use class-weighted loss function during training'\n",
    "        },\n",
    "        'dataset_structure': {\n",
    "            'splits': ['Training', 'Validation', 'Testing'],\n",
    "            'classes': classes,\n",
    "            'image_size': config['target_size'],\n",
    "            'format': 'grayscale',\n",
    "            'preprocessing_applied': ['grayscale_conversion', 'resize_224x224', 'CLAHE']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save to JSON\n",
    "    metadata_path = processed_path / 'preprocessing_metadata.json'\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"METADATA SAVED\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nðŸ“„ File: {metadata_path}\")\n",
    "    print(f\"\\nðŸŽ¯ Class Weights (for model.fit()):\")\n",
    "    for idx, cls in enumerate(classes):\n",
    "        weight = class_weights[idx]\n",
    "        print(f\"   Class {idx} ({cls:20s}): {weight:.4f}\")\n",
    "    \n",
    "    print(f\"\\nâš–ï¸  Imbalance Analysis:\")\n",
    "    print(f\"   â€¢ Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "    print(f\"   â€¢ Minority Class: {classes[minority_idx]}\")\n",
    "    print(f\"   â€¢ Majority Class: {classes[majority_idx]}\")\n",
    "    print(f\"   â€¢ Recommendation: {metadata['imbalance_info']['recommendation']}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return metadata_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_preprocessing_summary(stats, processed_dir):\n",
    "    \"\"\"Print comprehensive preprocessing summary\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PREPROCESSING SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nðŸ“ Output Directory: {processed_dir}\")\n",
    "    print(f\"\\nðŸ“Š Processing Statistics:\")\n",
    "    print(f\"   â€¢ Total images processed: {stats['total_images']}\")\n",
    "    print(f\"   â€¢ Duplicates skipped: {stats['duplicate_count']}\")\n",
    "    print(f\"   â€¢ Failed: {len(stats.get('failed', []))}\")\n",
    "    \n",
    "    if stats.get('failed'):\n",
    "        print(f\"\\nâš ï¸  Failed Files:\")\n",
    "        for filename, error in stats['failed'][:5]:\n",
    "            print(f\"      - {filename}: {error}\")\n",
    "        if len(stats['failed']) > 5:\n",
    "            print(f\"      ... and {len(stats['failed']) - 5} more\")\n",
    "    \n",
    "    print(f\"\\nðŸ“¦ Images per Class:\")\n",
    "    for cls, count in stats['class_counts'].items():\n",
    "        print(f\"   â€¢ {cls:20s}: {count:4d} images\")\n",
    "    \n",
    "    print(f\"\\nâœ… Preprocessing Complete!\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Print summary\n",
    "print_preprocessing_summary(stats, processed_dataset)\n",
    "\n",
    "# Save metadata for training notebook\n",
    "metadata_path = save_preprocessing_metadata(processed_dataset, config, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61fe3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
